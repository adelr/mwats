{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:Impact,Arial;font-size:50px\">Load</h1>\n",
    "<p> This code loads the raw data from the VAST pipeline for the MWATS survey and adds additional columns that are needed for the analysis. These are:\n",
    "    \n",
    "    1.) Image pointing centre (for each flux measurement).\n",
    "    2.) Distance from the pointing centre for each flux measurement (in degrees). \n",
    "    3.) Image gain. The mulitplicative factor that has been applied to the image to give the raw_peak_flux value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_distance_on_unit_sphere(df):\n",
    "    degrees_to_radians = np.pi/180.0\n",
    "    phi1 = df.ra*degrees_to_radians\n",
    "    phi2 = df.im_ra*degrees_to_radians\n",
    "\n",
    "    theta1 = df.dec*degrees_to_radians\n",
    "    theta2 = df.im_dec*degrees_to_radians\n",
    "    \n",
    "    cosine = (np.cos(phi1)*np.cos(phi2)*np.cos(theta1 - theta2) +\n",
    "           np.sin(phi1)*np.sin(phi2))\n",
    "    dist_from_centre = np.arccos(cosine)\n",
    "    return (dist_from_centre/3.142)*180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 3.45 s, total: 25.4 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the raw data file. \n",
    "raw_data = pd.read_parquet('data/mwats_27_sept_full.parq', engine='fastparquet')\n",
    "raw_data.drop(columns=['fit', \n",
    "                       'blind_detection', \n",
    "                       'polarisation',\n",
    "                       'band',\n",
    "                       'image_id',\n",
    "                       'extname',\n",
    "                       'cube_id',\n",
    "                       'good_fit',\n",
    "                       'fit_flags',\n",
    "                       'flux_gain',\n",
    "                       'pbcorr', \n",
    "                       'peak_pixel'], \n",
    "              axis=1, inplace=True)\n",
    "\n",
    "raw_data['raw_peak_flux'] = raw_data['raw_peak_flux']*(1.0/1000.0) # Conversion to Jy\n",
    "\n",
    "raw_data['datetime'] = pd.to_datetime(raw_data.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data file containing the locations of the image image-centres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing = pd.read_table('pointing_centres.txt', ',')\n",
    "pointing['Image'] = pointing['Image'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the image centres data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.9 s, sys: 7.4 s, total: 29.3 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_data = (pd.merge(raw_data, pointing, left_on='cube_name', right_on='Image')\n",
    "                .rename(columns = {'RA':'im_ra', 'DEC':'im_dec'}) # Rename the columns\n",
    "                .drop(columns=['cube_name'], axis=1) # Get rid of the \"cube_name\" column as we now have \"Image\"\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the distance between the source and the image centre ( then create column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 105 ms, total: 1.59 s\n",
      "Wall time: 402 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_data['distance'] = vectorized_distance_on_unit_sphere(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add in the gains to the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 3.15 s, total: 14 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gains = pd.read_table('all_gains.txt', ',')\n",
    "raw_data = pd.merge(raw_data, gains, left_on='Image', right_on='Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the reduced data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.6 s, sys: 6.91 s, total: 48.5 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_data.to_parquet('mwats_raw_data.parq', engine='fastparquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyviz",
   "language": "python",
   "name": "pyviz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
